# å¤§æ¨¡å‹ï¼ˆLLMsï¼‰langchainé¢

1. ä»€ä¹ˆæ˜¯ LangChain?
    
    <aside>
    ğŸ’¡ [https://python.langchain.com/docs/get_started/introduction](https://python.langchain.com/docs/get_started/introduction)
    
    LangChain æ˜¯ä¸€ä¸ªåŸºäºè¯­è¨€æ¨¡å‹çš„æ¡†æ¶ï¼Œç”¨äºæ„å»ºèŠå¤©æœºå™¨äººã€ç”Ÿæˆå¼é—®ç­”ï¼ˆGQAï¼‰ã€æ‘˜è¦ç­‰åŠŸèƒ½ã€‚å®ƒçš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä¸åŒçš„ç»„ä»¶â€œé“¾â€åœ¨ä¸€èµ·ï¼Œä»¥åˆ›å»ºæ›´é«˜çº§çš„è¯­è¨€æ¨¡å‹åº”ç”¨ã€‚LangChain çš„èµ·æºå¯ä»¥è¿½æº¯åˆ° 2022 å¹´ 10 æœˆï¼Œç”±åˆ›é€ è€… Harrison Chase åœ¨é‚£æ—¶æäº¤äº†ç¬¬ä¸€ä¸ªç‰ˆæœ¬ã€‚ä¸ Bitcoin ä¸åŒï¼ŒBitcoin æ˜¯åœ¨ 2009 å¹´ç”±ä¸€ä½ä½¿ç”¨åŒ–å Satoshi Nakamoto çš„æœªçŸ¥äººå£«åˆ›å»ºçš„ï¼Œå®ƒæ˜¯ä¸€ç§å»ä¸­å¿ƒåŒ–çš„åŠ å¯†è´§å¸ã€‚è€Œ LangChain æ˜¯å›´ç»•è¯­è¨€æ¨¡å‹æ„å»ºçš„æ¡†æ¶ã€‚
    
    </aside>
    
2. LangChain åŒ…å«å“ªäº› æ ¸å¿ƒæ¦‚å¿µï¼Ÿ
    1. LangChain ä¸­ Components and Chains æ˜¯ä»€ä¹ˆï¼Ÿ
        
        <aside>
        ğŸ’¡ [https://python.langchain.com/docs/modules/chains/](https://python.langchain.com/docs/modules/chains/)
        
        Components and Chains are key concepts in the LangChain framework.
        
        Components refer to the individual building blocks or modules that make up the LangChain framework. These components can include language models, data preprocessors, response generators, and other functionalities. Each component is responsible for a specific task or functionality within the language model application.
        
        Chains, on the other hand, are the connections or links between these components. They define the flow of data and information within the language model application. Chains allow the output of one component to serve as the input for another component, enabling the creation of more advanced language models.
        
        In summary, Components are the individual modules or functionalities within the LangChain framework, while Chains define the connections and flow of data between these components.
        
        Here's an example to illustrate the concept of Components and Chains in LangChain:
        
        ```python
        from langchain import Component, Chain
        
        # Define components
        preprocessor = Component("Preprocessor")
        language_model = Component("Language Model")
        response_generator = Component("Response Generator")
        
        # Define chains
        chain1 = Chain(preprocessor, language_model)
        chain2 = Chain(language_model, response_generator)
        
        # Execute chains
        input_data = "Hello, how are you?"
        processed_data = chain1.execute(input_data)
        response = chain2.execute(processed_data)
        
        print(response)
        ```
        
        In the above example, we have three components: Preprocessor, Language Model, and Response Generator. We create two chains: chain1 connects the Preprocessor and Language Model, and chain2 connects the Language Model and Response Generator. The input data is passed through chain1 to preprocess it and then passed through chain2 to generate a response.
        
        This is a simplified example to demonstrate the concept of Components and Chains in LangChain. In a real-world scenario, you would have more complex chains with multiple components and data transformations.
        
        </aside>
        
    2. LangChain ä¸­ Prompt Templates and Values æ˜¯ä»€ä¹ˆï¼Ÿ
        
        <aside>
        ğŸ’¡ [https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/)
        
        Prompt Templates and Values are key concepts in the LangChain framework.
        
        Prompt Templates refer to predefined structures or formats that guide the generation of prompts for language models. These templates provide a consistent and standardized way to construct prompts by specifying the desired input and output formats. Prompt templates can include placeholders or variables that are later filled with specific values.
        
        Values, on the other hand, are the specific data or information that is used to fill in the placeholders or variables in prompt templates. These values can be dynamically generated or retrieved from external sources. They provide the necessary context or input for the language model to generate the desired output.
        
        Here's an example to illustrate the concept of Prompt Templates and Values in LangChain:
        
        ```python
        from langchain import PromptTemplate, Value
        
        # Define prompt template
        template = PromptTemplate("What is the capital of {country}?")
        
        # Define values
        country_value = Value("country", "France")
        
        # Generate prompt
        prompt = template.generate_prompt(values=[country_value])
        
        print(prompt)
        ```
        
        In the above example, we have a prompt template that asks for the capital of a country. The template includes a placeholderÂ **`{country}`**Â that will be filled with the actual country value. We define a value objectÂ **`country_value`**Â with the name "country" and the value "France". We then generate the prompt by passing the value object to the template'sÂ **`generate_prompt`**Â method.
        
        The generated prompt will be "What is the capital of France?".
        
        Prompt templates and values allow for flexible and dynamic generation of prompts in the LangChain framework. They enable the customization and adaptation of prompts based on specific requirements or scenarios.
        
        </aside>
        
    3. LangChain ä¸­ Example Selectors æ˜¯ä»€ä¹ˆï¼Ÿ
        
        <aside>
        ğŸ’¡ [https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/](https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/)
        
        Example Selectors are a feature in the LangChain framework that allow users to specify and retrieve specific examples or data points from a dataset. These selectors help in customizing the training or inference process by selecting specific examples that meet certain criteria or conditions.
        
        Example Selectors can be used in various scenarios, such as:
        
        1. Training data selection: Users can use example selectors to filter and select specific examples from a large training dataset. This can be useful when working with limited computational resources or when focusing on specific subsets of the data.
        2. Inference customization: Example selectors can be used to retrieve specific examples from a dataset during the inference process. This allows users to generate responses or predictions based on specific conditions or criteria.
        
        Here's an example to illustrate the concept of Example Selectors in LangChain:
        
        ```python
        from langchain import ExampleSelector
        
        # Define an example selector
        selector = ExampleSelector(condition="label=='positive'")
        
        # Retrieve examples based on the selector
        selected_examples = selector.select_examples(dataset)
        
        # Use the selected examples for training or inference
        for example in selected_examples:
            # Perform training or inference on the selected example
            ...
        ```
        
        In the above example, we define an example selector with a condition that selects examples with a label equal to "positive". We then use the selector to retrieve the selected examples from a dataset. These selected examples can be used for training or inference purposes.
        
        Example Selectors provide a flexible way to customize the data used in the LangChain framework. They allow users to focus on specific subsets of the data or apply specific criteria to select examples that meet their requirements.
        
        </aside>
        
    4. LangChain ä¸­ Output Parsers æ˜¯ä»€ä¹ˆï¼Ÿ
        
        <aside>
        ğŸ’¡ [https://python.langchain.com/docs/modules/model_io/output_parsers/](https://python.langchain.com/docs/modules/model_io/output_parsers/)
        
        Output Parsers are a feature in the LangChain framework that allow users to automatically detect and parse the output generated by the language model. These parsers are designed to handle different types of output, such as strings, lists, dictionaries, or even Pydantic models.
        
        Output Parsers provide a convenient way to process and manipulate the output of the language model without the need for manual parsing or conversion. They help in extracting relevant information from the output and enable further processing or analysis.
        
        Here's an example to illustrate the concept of Output Parsers in LangChain:
        
        ```python
        from langchain import llm_prompt, OutputParser
        
        # Define an output parser
        parser = OutputParser()
        
        # Apply the output parser to a function
        @llm_prompt(output_parser=parser)
        def generate_response(input_text):
            # Generate response using the language model
            response = language_model.generate(input_text)
            return response
        
        # Generate a response
        input_text = "Hello, how are you?"
        response = generate_response(input_text)
        
        # Parse the output
        parsed_output = parser.parse_output(response)
        
        # Process the parsed output
        processed_output = process_output(parsed_output)
        
        print(processed_output)
        ```
        
        In the above example, we define an output parser and apply it to theÂ **`generate_response`**Â function using theÂ **`llm_prompt`**Â decorator. The output parser automatically detects the type of the output and provides the parsed output. We can then further process or analyze the parsed output as needed.
        
        Output Parsers provide a flexible and efficient way to handle the output of the language model in the LangChain framework. They simplify the post-processing of the output and enable seamless integration with other components or systems.
        
        </aside>
        
    5. LangChain ä¸­ Indexes and Retrievers æ˜¯ä»€ä¹ˆï¼Ÿ
        
        <aside>
        ğŸ’¡ [https://python.langchain.com/docs/modules/data_connection/retrievers/](https://python.langchain.com/docs/modules/data_connection/retrievers/)
        
        [https://python.langchain.com/docs/modules/data_connection/indexing](https://python.langchain.com/docs/modules/data_connection/indexing)
        
        Indexes and Retrievers are components in the Langchain framework.
        
        Indexes are used to store and organize data for efficient retrieval. Langchain supports multiple types of document indexes, such as InMemoryExactNNIndex, HnswDocumentIndex, WeaviateDocumentIndex, ElasticDocIndex, and QdrantDocumentIndex. Each index has its own characteristics and is suited for different use cases. For example, InMemoryExactNNIndex is suitable for small datasets that can be stored in memory, while HnswDocumentIndex is lightweight and suitable for small to medium-sized datasets.
        
        Retrievers, on the other hand, are used to retrieve relevant documents from the indexes based on a given query. Langchain provides different types of retrievers, such as MetalRetriever and DocArrayRetriever. MetalRetriever is used with the Metal platform for semantic search and retrieval, while DocArrayRetriever is used with the DocArray tool for managing multi-modal data.
        
        Overall, indexes and retrievers are essential components in Langchain for efficient data storage and retrieval.
        
        </aside>
        
    6. LangChain ä¸­ Chat Message History æ˜¯ä»€ä¹ˆï¼Ÿ
        
        <aside>
        ğŸ’¡ [https://python.langchain.com/docs/modules/memory/chat_messages/](https://python.langchain.com/docs/modules/memory/chat_messages/)
        
        Chat Message History æ˜¯ Langchain æ¡†æ¶ä¸­çš„ä¸€ä¸ªç»„ä»¶ï¼Œç”¨äºå­˜å‚¨å’Œç®¡ç†èŠå¤©æ¶ˆæ¯çš„å†å²è®°å½•ã€‚å®ƒå¯ä»¥è·Ÿè¸ªå’Œä¿å­˜ç”¨æˆ·å’ŒAIä¹‹é—´çš„å¯¹è¯ï¼Œä»¥ä¾¿åœ¨éœ€è¦æ—¶è¿›è¡Œæ£€ç´¢å’Œåˆ†æã€‚
        
        Langchain æä¾›äº†ä¸åŒçš„ Chat Message History å®ç°ï¼ŒåŒ…æ‹¬ StreamlitChatMessageHistoryã€CassandraChatMessageHistory å’Œ MongoDBChatMessageHistoryã€‚
        
        - StreamlitChatMessageHistoryï¼šç”¨äºåœ¨ Streamlit åº”ç”¨ç¨‹åºä¸­å­˜å‚¨å’Œä½¿ç”¨èŠå¤©æ¶ˆæ¯å†å²è®°å½•ã€‚å®ƒä½¿ç”¨ Streamlit ä¼šè¯çŠ¶æ€æ¥å­˜å‚¨æ¶ˆæ¯ï¼Œå¹¶å¯ä»¥ä¸ ConversationBufferMemory å’Œé“¾æˆ–ä»£ç†ä¸€èµ·ä½¿ç”¨ã€‚
        - CassandraChatMessageHistoryï¼šä½¿ç”¨ Apache Cassandra æ•°æ®åº“å­˜å‚¨èŠå¤©æ¶ˆæ¯å†å²è®°å½•ã€‚Cassandra æ˜¯ä¸€ç§é«˜åº¦å¯æ‰©å±•å’Œé«˜å¯ç”¨çš„ NoSQL æ•°æ®åº“ï¼Œé€‚ç”¨äºå­˜å‚¨å¤§é‡æ•°æ®ã€‚
        - MongoDBChatMessageHistoryï¼šä½¿ç”¨ MongoDB æ•°æ®åº“å­˜å‚¨èŠå¤©æ¶ˆæ¯å†å²è®°å½•ã€‚MongoDB æ˜¯ä¸€ç§é¢å‘æ–‡æ¡£çš„ NoSQL æ•°æ®åº“ï¼Œä½¿ç”¨ç±»ä¼¼ JSON çš„æ–‡æ¡£è¿›è¡Œå­˜å‚¨ã€‚
        
        æ‚¨å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚é€‰æ‹©é€‚åˆçš„ Chat Message History å®ç°ï¼Œå¹¶å°†å…¶é›†æˆåˆ° Langchain æ¡†æ¶ä¸­ï¼Œä»¥ä¾¿è®°å½•å’Œç®¡ç†èŠå¤©æ¶ˆæ¯çš„å†å²è®°å½•ã€‚
        
        è¯·æ³¨æ„ï¼ŒChat Message History çš„å…·ä½“ç”¨æ³•å’Œå®ç°ç»†èŠ‚å¯ä»¥å‚è€ƒ Langchain çš„å®˜æ–¹æ–‡æ¡£å’Œç¤ºä¾‹ä»£ç ã€‚
        
        </aside>
        
    7. LangChain ä¸­ Agents and Toolkits æ˜¯ä»€ä¹ˆï¼Ÿ
        
        <aside>
        ğŸ’¡ [https://python.langchain.com/docs/modules/agents/](https://python.langchain.com/docs/modules/agents/)
        
        [https://python.langchain.com/docs/modules/agents/toolkits/](https://python.langchain.com/docs/modules/agents/toolkits/)
        
        Agents and Toolkits in LangChain are components that are used to create and manage conversational agents.
        
        Agents are responsible for determining the next action to take based on the current state of the conversation. They can be created using different approaches, such as OpenAI Function Calling, Plan-and-execute Agent, Baby AGI, and Auto GPT. These approaches provide different levels of customization and functionality for building agents.
        
        Toolkits, on the other hand, are collections of tools that can be used by agents to perform specific tasks or actions. Tools are functions or methods that take input and produce output. They can be custom-built or pre-defined and cover a wide range of functionalities, such as language processing, data manipulation, and external API integration.
        
        By combining agents and toolkits, developers can create powerful conversational agents that can understand user inputs, generate appropriate responses, and perform various tasks based on the given context.
        
        Here is an example of how to create an agent using LangChain:
        
        ```python
        from langchain.chat_models import ChatOpenAI
        from langchain.agents import tool
        
        # Load the language model
        llm = ChatOpenAI(temperature=0)
        
        # Define a custom tool
        @tool
        def get_word_length(word: str) -> int:
            """Returns the length of a word."""
            return len(word)
        
        # Create the agent
        agent = {
            "input": lambda x: x["input"],
            "agent_scratchpad": lambda x: format_to_openai_functions(x['intermediate_steps'])
        } | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()
        
        # Invoke the agent
        output = agent.invoke({
            "input": "how many letters in the word educa?",
            "intermediate_steps": []
        })
        
        # Print the result
        print(output.return_values["output"])
        ```
        
        This is just a basic example, and there are many more features and functionalities available in LangChain for building and customizing agents and toolkits. You can refer to the LangChain documentation for more details and examples.
        
        </aside>
        
3. ä»€ä¹ˆæ˜¯ LangChain Agent?
    
    <aside>
    ğŸ’¡ [https://python.langchain.com/docs/modules/agents/](https://python.langchain.com/docs/modules/agents/)
    
    LangChain Agent æ˜¯ LangChain æ¡†æ¶ä¸­çš„ä¸€ä¸ªç»„ä»¶ï¼Œç”¨äºåˆ›å»ºå’Œç®¡ç†å¯¹è¯ä»£ç†ã€‚ä»£ç†æ˜¯æ ¹æ®å½“å‰å¯¹è¯çŠ¶æ€ç¡®å®šä¸‹ä¸€æ­¥æ“ä½œçš„ç»„ä»¶ã€‚LangChain æä¾›äº†å¤šç§åˆ›å»ºä»£ç†çš„æ–¹æ³•ï¼ŒåŒ…æ‹¬ OpenAI Function Callingã€Plan-and-execute Agentã€Baby AGI å’Œ Auto GPT ç­‰ã€‚è¿™äº›æ–¹æ³•æä¾›äº†ä¸åŒçº§åˆ«çš„è‡ªå®šä¹‰å’ŒåŠŸèƒ½ï¼Œç”¨äºæ„å»ºä»£ç†ã€‚
    
    ä»£ç†å¯ä»¥ä½¿ç”¨å·¥å…·åŒ…æ‰§è¡Œç‰¹å®šçš„ä»»åŠ¡æˆ–æ“ä½œã€‚å·¥å…·åŒ…æ˜¯ä»£ç†ä½¿ç”¨çš„ä¸€ç»„å·¥å…·ï¼Œç”¨äºæ‰§è¡Œç‰¹å®šçš„åŠŸèƒ½ï¼Œå¦‚è¯­è¨€å¤„ç†ã€æ•°æ®æ“ä½œå’Œå¤–éƒ¨ API é›†æˆã€‚å·¥å…·å¯ä»¥æ˜¯è‡ªå®šä¹‰æ„å»ºçš„ï¼Œä¹Ÿå¯ä»¥æ˜¯é¢„å®šä¹‰çš„ï¼Œæ¶µç›–äº†å¹¿æ³›çš„åŠŸèƒ½ã€‚
    
    é€šè¿‡ç»“åˆä»£ç†å’Œå·¥å…·åŒ…ï¼Œå¼€å‘äººå‘˜å¯ä»¥åˆ›å»ºå¼ºå¤§çš„å¯¹è¯ä»£ç†ï¼Œèƒ½å¤Ÿç†è§£ç”¨æˆ·è¾“å…¥ï¼Œç”Ÿæˆé€‚å½“çš„å›å¤ï¼Œå¹¶æ ¹æ®ç»™å®šçš„ä¸Šä¸‹æ–‡æ‰§è¡Œå„ç§ä»»åŠ¡ã€‚
    
    ä»¥ä¸‹æ˜¯ä½¿ç”¨ LangChain åˆ›å»ºä»£ç†çš„ç¤ºä¾‹ä»£ç ï¼š
    
    ```python
    from langchain.chat_models import ChatOpenAI
    from langchain.agents import tool
    
    # åŠ è½½è¯­è¨€æ¨¡å‹
    llm = ChatOpenAI(temperature=0)
    
    # å®šä¹‰è‡ªå®šä¹‰å·¥å…·
    @tool
    def get_word_length(word: str) -> int:
        """è¿”å›å•è¯çš„é•¿åº¦ã€‚"""
        return len(word)
    
    # åˆ›å»ºä»£ç†
    agent = {
        "input": lambda x: x["input"],
        "agent_scratchpad": lambda x: format_to_openai_functions(x['intermediate_steps'])
    } | prompt | llm_with_tools | OpenAIFunctionsAgentOutputParser()
    
    # è°ƒç”¨ä»£ç†
    output = agent.invoke({
        "input": "å•è¯ educa ä¸­æœ‰å¤šå°‘ä¸ªå­—æ¯ï¼Ÿ",
        "intermediate_steps": []
    })
    
    # æ‰“å°ç»“æœ
    print(output.return_values["output"])
    ```
    
    è¿™åªæ˜¯ä¸€ä¸ªåŸºæœ¬ç¤ºä¾‹ï¼ŒLangChain ä¸­è¿˜æœ‰æ›´å¤šåŠŸèƒ½å’ŒåŠŸèƒ½å¯ç”¨äºæ„å»ºå’Œè‡ªå®šä¹‰ä»£ç†å’Œå·¥å…·åŒ…ã€‚æ‚¨å¯ä»¥å‚è€ƒ LangChain æ–‡æ¡£ä»¥è·å–æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œç¤ºä¾‹ã€‚
    
    </aside>
    
4. å¦‚ä½•ä½¿ç”¨ LangChain ?
    
    <aside>
    ğŸ’¡ [https://python.langchain.com/docs/get_started/quickstart](https://python.langchain.com/docs/get_started/quickstart)
    
    To use LangChain, you first need to sign up for an API key at platform.langchain.com. Once you have your API key, you can install the Python library and write a simple Python script to call the LangChain API. Here is some sample code to get started:
    
    ```
    import langchain
    
    api_key = "YOUR_API_KEY"
    
    langchain.set_key(api_key)
    
    response = langchain.ask("What is the capital of France?")
    
    print(response.response)
    ```
    
    This code will send the question "What is the capital of France?" to the LangChain API and print the response. You can customize the request by providing parameters like max_tokens, temperature, etc. The LangChain Python library documentation has more details on the available options.
    
    </aside>
    
5. LangChain æ”¯æŒå“ªäº›åŠŸèƒ½?
    
    <aside>
    ğŸ’¡
    
    LangChainæ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
    
    1. ç¼–å†™å¸–å­çš„çŸ­æ ‡é¢˜ï¼šä½¿ç”¨**`write_me_short_post`**å‡½æ•°å¯ä»¥ç”Ÿæˆå…³äºç‰¹å®šä¸»é¢˜ã€å¹³å°å’Œå—ä¼—çš„çŸ­æ ‡é¢˜ã€‚è¯¥å‡½æ•°çš„å‚æ•°åŒ…æ‹¬**`topic`**ï¼ˆä¸»é¢˜ï¼‰ã€**`platform`**ï¼ˆå¹³å°ï¼Œé»˜è®¤ä¸ºTwitterï¼‰å’Œ**`audience`**ï¼ˆå—ä¼—ï¼Œé»˜è®¤ä¸ºå¼€å‘äººå‘˜ï¼‰ã€‚ç”Ÿæˆçš„æ ‡é¢˜åº”è¯¥åœ¨15ä¸ªå•è¯ä»¥å†…ã€‚
    2. æ¨¡æ‹Ÿå¯¹è¯ï¼šä½¿ç”¨**`simulate_conversation`**å‡½æ•°å¯ä»¥æ¨¡æ‹Ÿå¯¹è¯ï¼ŒåŒ…æ‹¬ç³»ç»Ÿæ¶ˆæ¯ã€ç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹æ¶ˆæ¯ã€‚å¯¹è¯å¯ä»¥æ ¹æ®è§’è‰²ï¼ˆå¦‚åŠ©æ‰‹ã€ç”¨æˆ·ã€ç³»ç»Ÿï¼‰è¿›è¡Œäº¤äº’ï¼Œå¹¶å¯ä»¥åŒ…å«å†å²è®°å½•ã€‚è¿™å¯¹äºè®­ç»ƒèŠå¤©æ¨¡å‹éå¸¸æœ‰ç”¨ã€‚
    3. å¯é€‰éƒ¨åˆ†ï¼šå¯ä»¥åœ¨æç¤ºä¸­å®šä¹‰å¯é€‰éƒ¨åˆ†ï¼Œåªæœ‰åœ¨æ‰€æœ‰å‚æ•°éƒ½ä¸ä¸ºç©ºæ—¶æ‰ä¼šæ¸²æŸ“è¯¥éƒ¨åˆ†ã€‚è¿™å¯ä»¥é€šè¿‡åœ¨æç¤ºä¸­ä½¿ç”¨**`{? ... ?}`**è¯­æ³•æ¥å®ç°ã€‚
    4. è¾“å‡ºè§£æå™¨ï¼š**`llm_prompt`**è£…é¥°å™¨å¯ä»¥è‡ªåŠ¨æ£€æµ‹è¾“å‡ºç±»å‹ï¼Œå¹¶æä¾›ç›¸åº”çš„è§£æå™¨ã€‚æ”¯æŒçš„è¾“å‡ºç±»å‹åŒ…æ‹¬å­—ç¬¦ä¸²ã€åˆ—è¡¨ã€å­—å…¸å’ŒPydanticæ¨¡å‹ã€‚
    
    ä»¥ä¸Šæ˜¯LangChainæ”¯æŒçš„ä¸€äº›åŠŸèƒ½ã€‚æ‚¨å¯ä»¥æ ¹æ®å…·ä½“çš„éœ€æ±‚ä½¿ç”¨è¿™äº›åŠŸèƒ½æ¥åˆ›å»ºç”Ÿäº§å°±ç»ªçš„èŠå¤©åº”ç”¨ç¨‹åºã€‚
    
    </aside>
    
    <aside>
    ğŸ’¡
    
    LangChainæ”¯æŒä»¥ä¸‹åŠŸèƒ½ï¼š
    
    - ç¼–å†™è‡ªå®šä¹‰çš„LangChainæç¤ºå’Œé“¾å¼ä»£ç çš„è¯­æ³•ç³–
    - ä½¿ç”¨IDEå†…ç½®çš„æ”¯æŒè¿›è¡Œæç¤ºã€ç±»å‹æ£€æŸ¥å’Œå¼¹å‡ºæ–‡æ¡£ï¼Œä»¥å¿«é€ŸæŸ¥çœ‹å‡½æ•°çš„æç¤ºå’Œå‚æ•°
    - åˆ©ç”¨LangChainç”Ÿæ€ç³»ç»Ÿçš„å…¨éƒ¨åŠŸèƒ½
    - æ·»åŠ å¯¹å¯é€‰å‚æ•°çš„æ”¯æŒ
    - é€šè¿‡å°†å‚æ•°ç»‘å®šåˆ°ä¸€ä¸ªç±»æ¥è½»æ¾å…±äº«å‚æ•°
    - æ”¯æŒä¼ é€’å†…å­˜å’Œå›è°ƒå‡½æ•°
    - ç®€åŒ–çš„æµå¼å¤„ç†
    - å®šä¹‰èŠå¤©æ¶ˆæ¯æç¤º
    - å¯é€‰éƒ¨åˆ†
    - è¾“å‡ºè§£æå™¨
    - æ”¯æŒæ›´å¤æ‚çš„æ•°æ®ç»“æ„
    </aside>
    
6. ä»€ä¹ˆæ˜¯ LangChain model?
    
    <aside>
    ğŸ’¡
    
    LangChain model æ˜¯ä¸€ä¸ªåŸºäºè¯­è¨€æ¨¡å‹çš„æ¡†æ¶ï¼Œç”¨äºæ„å»ºèŠå¤©æœºå™¨äººã€ç”Ÿæˆå¼é—®ç­”ï¼ˆGQAï¼‰ã€æ‘˜è¦ç­‰åŠŸèƒ½ã€‚LangChain çš„æ ¸å¿ƒæ€æƒ³æ˜¯å¯ä»¥å°†ä¸åŒçš„ç»„ä»¶â€œé“¾â€åœ¨ä¸€èµ·ï¼Œä»¥åˆ›å»ºæ›´é«˜çº§çš„è¯­è¨€æ¨¡å‹åº”ç”¨ã€‚
    
    </aside>
    
    <aside>
    ğŸ’¡ LangChain modelæ˜¯ä¸€ç§åŸºäºå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„æ¨¡å‹ã€‚å®ƒæ˜¯LangChainæ¡†æ¶çš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ï¼Œç”¨äºæ„å»ºåŸºäºè¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åºã€‚LangChainæ¨¡å‹å¯ä»¥ç”¨äºèŠå¤©æœºå™¨äººã€ç”Ÿæˆå¼é—®ç­”ã€æ‘˜è¦ç­‰å¤šç§åº”ç”¨ã€‚å®ƒæä¾›äº†ä¸€ç§æ ‡å‡†çš„æ¥å£ï¼Œä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿä½¿ç”¨LLMæ¥å¤„ç†è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚LangChainæ¨¡å‹çš„ç›®æ ‡æ˜¯ç®€åŒ–å¼€å‘è¿‡ç¨‹ï¼Œä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿæ›´è½»æ¾åœ°æ„å»ºå¼ºå¤§çš„è¯­è¨€æ¨¡å‹åº”ç”¨ç¨‹åºã€‚
    
    </aside>
    
7. LangChain åŒ…å«å“ªäº›ç‰¹ç‚¹?
    
    <aside>
    ğŸ’¡
    
    LangChain åŒ…å«ä»¥ä¸‹ç‰¹ç‚¹ï¼š
    
    - ç¼–å†™è‡ªå®šä¹‰çš„LangChainæç¤ºå’Œé“¾å¼ä»£ç çš„è¯­æ³•ç³–
    - ä½¿ç”¨IDEå†…ç½®çš„æ”¯æŒè¿›è¡Œæç¤ºã€ç±»å‹æ£€æŸ¥å’Œå¼¹å‡ºæ–‡æ¡£ï¼Œä»¥å¿«é€ŸæŸ¥çœ‹å‡½æ•°çš„æç¤ºå’Œå‚æ•°
    - åˆ©ç”¨LangChainç”Ÿæ€ç³»ç»Ÿçš„å…¨éƒ¨åŠŸèƒ½
    - æ·»åŠ å¯¹å¯é€‰å‚æ•°çš„æ”¯æŒ
    - é€šè¿‡å°†å‚æ•°ç»‘å®šåˆ°ä¸€ä¸ªç±»æ¥è½»æ¾å…±äº«å‚æ•°
    - æ”¯æŒä¼ é€’å†…å­˜å’Œå›è°ƒå‡½æ•°
    - ç®€åŒ–çš„æµå¼å¤„ç†
    - å®šä¹‰èŠå¤©æ¶ˆæ¯æç¤º
    - å¯é€‰éƒ¨åˆ†
    - è¾“å‡ºè§£æå™¨
    - æ”¯æŒæ›´å¤æ‚çš„æ•°æ®ç»“æ„
    </aside>
    
8. LangChain å¦‚ä½•ä½¿ç”¨?
    1. LangChain å¦‚ä½•è°ƒç”¨ LLMs ç”Ÿæˆå›å¤ï¼Ÿ
        
        <aside>
        ğŸ’¡
        
        è¦è°ƒç”¨LLMsç”Ÿæˆå›å¤ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨LangChainæ¡†æ¶æä¾›çš„LLMChainç±»ã€‚LLMChainç±»æ˜¯LangChainçš„ä¸€ä¸ªç»„ä»¶ï¼Œç”¨äºä¸è¯­è¨€æ¨¡å‹è¿›è¡Œäº¤äº’å¹¶ç”Ÿæˆå›å¤ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ä»£ç ç‰‡æ®µï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨LLMChainç±»è°ƒç”¨LLMsç”Ÿæˆå›å¤ï¼š
        
        ```python
        from langchain.llms import OpenAI
        from langchain.chains import LLMChain
        
        llm = OpenAI(temperature=0.9)  # åˆ›å»ºLLMå®ä¾‹
        prompt = "ç”¨æˆ·çš„é—®é¢˜"  # è®¾ç½®ç”¨æˆ·çš„é—®é¢˜
        
        # åˆ›å»ºLLMChainå®ä¾‹
        chain = LLMChain(llm=llm, prompt=prompt)
        
        # è°ƒç”¨LLMsç”Ÿæˆå›å¤
        response = chain.generate()
        
        print(response)  # æ‰“å°ç”Ÿæˆçš„å›å¤
        ```
        
        åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ªLLMå®ä¾‹ï¼Œç„¶åè®¾ç½®äº†ç”¨æˆ·çš„é—®é¢˜ä½œä¸ºLLMChainçš„promptã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬è°ƒç”¨LLMChainçš„generateæ–¹æ³•æ¥ç”Ÿæˆå›å¤ã€‚æœ€åï¼Œæˆ‘ä»¬æ‰“å°ç”Ÿæˆçš„å›å¤ã€‚
        
        è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦è‡ªå®šä¹‰LLMçš„å‚æ•°ï¼Œä¾‹å¦‚æ¸©åº¦ï¼ˆtemperatureï¼‰ã€æœ€å¤§ä»¤ç‰Œæ•°ï¼ˆmax_tokensï¼‰ç­‰ã€‚LangChainæ–‡æ¡£ä¸­æœ‰å…³äºLLMChainç±»å’ŒLLMå‚æ•°çš„æ›´å¤šè¯¦ç»†ä¿¡æ¯ã€‚
        
        </aside>
        
    2. LangChain å¦‚ä½•ä¿®æ”¹ æç¤ºæ¨¡æ¿ï¼Ÿ
        
        <aside>
        ğŸ’¡
        
        è¦ä¿®æ”¹LangChainçš„æç¤ºæ¨¡æ¿ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨LangChainæ¡†æ¶æä¾›çš„**`ChatPromptTemplate`**ç±»ã€‚**`ChatPromptTemplate`**ç±»å…è®¸æ‚¨åˆ›å»ºè‡ªå®šä¹‰çš„èŠå¤©æ¶ˆæ¯æç¤ºï¼Œå¹¶æ ¹æ®éœ€è¦è¿›è¡Œä¿®æ”¹ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ä»£ç ç‰‡æ®µï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨**`ChatPromptTemplate`**ç±»ä¿®æ”¹æç¤ºæ¨¡æ¿ï¼š
        
        ```python
        from langchain.prompts import ChatPromptTemplate
        
        # åˆ›å»ºä¸€ä¸ªç©ºçš„ChatPromptTemplateå®ä¾‹
        template = ChatPromptTemplate()
        
        # æ·»åŠ èŠå¤©æ¶ˆæ¯æç¤º
        template.add_message("system", "You are a helpful AI bot.")
        template.add_message("human", "Hello, how are you doing?")
        template.add_message("ai", "I'm doing well, thanks!")
        template.add_message("human", "What is your name?")
        
        # ä¿®æ”¹æç¤ºæ¨¡æ¿
        template.set_message_content(0, "You are a helpful AI assistant.")
        template.set_message_content(3, "What is your name? Please tell me.")
        
        # æ ¼å¼åŒ–èŠå¤©æ¶ˆæ¯
        messages = template.format_messages()
        
        print(messages)
        ```
        
        åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ªç©ºçš„**`ChatPromptTemplate`**å®ä¾‹ã€‚ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨**`add_message`**æ–¹æ³•æ·»åŠ äº†èŠå¤©æ¶ˆæ¯æç¤ºã€‚æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨**`set_message_content`**æ–¹æ³•ä¿®æ”¹äº†ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªèŠå¤©æ¶ˆæ¯çš„å†…å®¹ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨**`format_messages`**æ–¹æ³•æ ¼å¼åŒ–èŠå¤©æ¶ˆæ¯ï¼Œå¹¶æ‰“å°å‡ºæ¥ã€‚
        
        è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ ã€åˆ é™¤å’Œä¿®æ”¹èŠå¤©æ¶ˆæ¯æç¤ºã€‚**`ChatPromptTemplate`**ç±»æä¾›äº†å¤šç§æ–¹æ³•æ¥æ“ä½œæç¤ºæ¨¡æ¿ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œç¤ºä¾‹ä»£ç å¯ä»¥åœ¨LangChainæ–‡æ¡£ä¸­æ‰¾åˆ°ã€‚
        
        </aside>
        
    3. LangChain å¦‚ä½•é“¾æ¥å¤šä¸ªç»„ä»¶å¤„ç†ä¸€ä¸ªç‰¹å®šçš„ä¸‹æ¸¸ä»»åŠ¡ï¼Ÿ
        
        <aside>
        ğŸ’¡
        
        è¦é“¾æ¥å¤šä¸ªç»„ä»¶å¤„ç†ä¸€ä¸ªç‰¹å®šçš„ä¸‹æ¸¸ä»»åŠ¡ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨LangChainæ¡†æ¶æä¾›çš„**`Chain`**ç±»ã€‚**`Chain`**ç±»å…è®¸æ‚¨å°†å¤šä¸ªç»„ä»¶è¿æ¥åœ¨ä¸€èµ·ï¼Œä»¥ä¾¿æŒ‰é¡ºåºå¤„ç†ä»»åŠ¡ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ä»£ç ç‰‡æ®µï¼Œå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨**`Chain`**ç±»é“¾æ¥å¤šä¸ªç»„ä»¶å¤„ç†ä¸‹æ¸¸ä»»åŠ¡ï¼š
        
        ```python
        from langchain.chains import Chain
        from langchain.components import Component1, Component2, Component3
        
        # åˆ›å»ºç»„ä»¶å®ä¾‹
        component1 = Component1()
        component2 = Component2()
        component3 = Component3()
        
        # åˆ›å»ºChainå®ä¾‹å¹¶æ·»åŠ ç»„ä»¶
        chain = Chain()
        chain.add_component(component1)
        chain.add_component(component2)
        chain.add_component(component3)
        
        # å¤„ç†ä¸‹æ¸¸ä»»åŠ¡
        output = chain.process_downstream_task()
        
        print(output)
        ```
        
        åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºäº†å¤šä¸ªç»„ä»¶çš„å®ä¾‹ï¼Œä¾‹å¦‚**`Component1`**ã€**`Component2`**å’Œ**`Component3`**ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª**`Chain`**å®ä¾‹ï¼Œå¹¶ä½¿ç”¨**`add_component`**æ–¹æ³•å°†è¿™äº›ç»„ä»¶æ·»åŠ åˆ°é“¾ä¸­ã€‚æœ€åï¼Œæˆ‘ä»¬è°ƒç”¨**`process_downstream_task`**æ–¹æ³•æ¥å¤„ç†ä¸‹æ¸¸ä»»åŠ¡ï¼Œå¹¶æ‰“å°è¾“å‡ºç»“æœã€‚
        
        è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ ã€åˆ é™¤å’Œä¿®æ”¹ç»„ä»¶ã€‚**`Chain`**ç±»æä¾›äº†å¤šç§æ–¹æ³•æ¥æ“ä½œé“¾ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œç¤ºä¾‹ä»£ç å¯ä»¥åœ¨LangChainæ–‡æ¡£ä¸­æ‰¾åˆ°ã€‚
        
        </aside>
        
    4. LangChain å¦‚ä½•Embedding & vector storeï¼Ÿ
        
        <aside>
        ğŸ’¡
        
        è¦åœ¨LangChainä¸­è¿›è¡ŒåµŒå…¥å’Œå‘é‡å­˜å‚¨ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨LangChainæ¡†æ¶æä¾›çš„**`Embedding`**å’Œ**`VectorStore`**ç±»ã€‚**`Embedding`**ç±»ç”¨äºå°†æ–‡æœ¬åµŒå…¥åˆ°å‘é‡ç©ºé—´ä¸­ï¼Œè€Œ**`VectorStore`**ç±»ç”¨äºå­˜å‚¨å’Œæ£€ç´¢åµŒå…¥å‘é‡ã€‚ä»¥ä¸‹æ˜¯ä¸€ä¸ªç¤ºä¾‹ä»£ç ç‰‡æ®µï¼Œå±•ç¤ºäº†å¦‚ä½•åœ¨LangChainä¸­è¿›è¡ŒåµŒå…¥å’Œå‘é‡å­˜å‚¨ï¼š
        
        ```python
        from langchain.embeddings import Embedding
        from langchain.vectorstore import VectorStore
        
        # åˆ›å»ºEmbeddingå®ä¾‹
        embedding = Embedding()
        
        # å°†æ–‡æœ¬åµŒå…¥åˆ°å‘é‡ç©ºé—´ä¸­
        embedding.embed("Hello, world!")
        
        # åˆ›å»ºVectorStoreå®ä¾‹
        vector_store = VectorStore()
        
        # å­˜å‚¨åµŒå…¥å‘é‡
        vector_store.store("hello", embedding.get_embedding())
        
        # æ£€ç´¢åµŒå…¥å‘é‡
        vector = vector_store.retrieve("hello")
        
        print(vector)
        ```
        
        åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåˆ›å»ºäº†ä¸€ä¸ª**`Embedding`**å®ä¾‹ï¼Œå¹¶ä½¿ç”¨**`embed`**æ–¹æ³•å°†æ–‡æœ¬åµŒå…¥åˆ°å‘é‡ç©ºé—´ä¸­ã€‚ç„¶åï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª**`VectorStore`**å®ä¾‹ï¼Œå¹¶ä½¿ç”¨**`store`**æ–¹æ³•å°†åµŒå…¥å‘é‡å­˜å‚¨åˆ°å‘é‡å­˜å‚¨ä¸­ã€‚æœ€åï¼Œæˆ‘ä»¬ä½¿ç”¨**`retrieve`**æ–¹æ³•æ£€ç´¢åµŒå…¥å‘é‡ï¼Œå¹¶æ‰“å°å‡ºæ¥ã€‚
        
        è¯·æ³¨æ„ï¼Œæ‚¨å¯ä»¥æ ¹æ®éœ€è¦æ·»åŠ ã€åˆ é™¤å’Œä¿®æ”¹åµŒå…¥å‘é‡ã€‚**`Embedding`**ç±»å’Œ**`VectorStore`**ç±»æä¾›äº†å¤šç§æ–¹æ³•æ¥æ“ä½œåµŒå…¥å’Œå‘é‡å­˜å‚¨ã€‚æ›´å¤šè¯¦ç»†ä¿¡æ¯å’Œç¤ºä¾‹ä»£ç å¯ä»¥åœ¨LangChainæ–‡æ¡£ä¸­æ‰¾åˆ°ã€‚
        
        </aside>
        
9. LangChain å­˜åœ¨å“ªäº›é—®é¢˜åŠæ–¹æ³•æ–¹æ¡ˆï¼Ÿ
    1. LangChain ä½æ•ˆçš„ä»¤ç‰Œä½¿ç”¨é—®é¢˜
        
        <aside>
        ğŸ’¡
        
        LangChainçš„tokenä½¿ç”¨æ˜¯é«˜æ•ˆçš„ã€‚LangChainä½¿ç”¨äº†ä¸€ç§ç§°ä¸º"token-based"çš„æ–¹æ³•æ¥å¤„ç†æ–‡æœ¬è¾“å…¥å’Œè¾“å‡ºã€‚è¿™ç§æ–¹æ³•å°†æ–‡æœ¬åˆ†è§£ä¸ºå°çš„å•å…ƒï¼Œç§°ä¸º"tokens"ï¼Œå¹¶å¯¹å®ƒä»¬è¿›è¡Œå¤„ç†ã€‚ç›¸æ¯”äºä¼ ç»Ÿçš„å­—ç¬¦æˆ–è¯è¯­çº§åˆ«çš„å¤„ç†ï¼Œä½¿ç”¨tokenså¯ä»¥æ›´é«˜æ•ˆåœ°å¤„ç†æ–‡æœ¬ã€‚
        
        LangChainè¿˜æä¾›äº†ä¸€äº›å‚æ•°ï¼Œå¦‚**`max_tokens`**å’Œ**`temperature`**ï¼Œå¯ä»¥ç”¨æ¥æ§åˆ¶ç”Ÿæˆå›å¤çš„é•¿åº¦å’Œå¤šæ ·æ€§ã€‚é€šè¿‡è°ƒæ•´è¿™äº›å‚æ•°ï¼Œå¼€å‘äººå‘˜å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚æ¥å¹³è¡¡ç”Ÿæˆå›å¤çš„æ•ˆç‡å’Œè´¨é‡ã€‚
        
        æ€»çš„æ¥è¯´ï¼ŒLangChainçš„tokenä½¿ç”¨æ˜¯é«˜æ•ˆçš„ï¼Œå¹¶ä¸”å¼€å‘äººå‘˜å¯ä»¥é€šè¿‡è°ƒæ•´å‚æ•°æ¥æ§åˆ¶ç”Ÿæˆå›å¤çš„æ•ˆæœã€‚
        
        </aside>
        
    2. LangChain æ–‡æ¡£çš„é—®é¢˜
    3. LangChain å¤ªå¤šæ¦‚å¿µå®¹æ˜“æ··æ·†ï¼Œè¿‡å¤šçš„â€œè¾…åŠ©â€å‡½æ•°é—®é¢˜
    4. LangChain è¡Œä¸ºä¸ä¸€è‡´å¹¶ä¸”éšè—ç»†èŠ‚é—®é¢˜
    5. LangChain ç¼ºä¹æ ‡å‡†çš„å¯äº’æ“ä½œæ•°æ®ç±»å‹é—®é¢˜
        
        <aside>
        ğŸ’¡ LangChainæä¾›äº†ä¸€ç§æ ‡å‡†çš„æ¥å£ï¼Œä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¤„ç†è‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ã€‚è™½ç„¶LangChainæ”¯æŒæ›´å¤æ‚çš„æ•°æ®ç»“æ„ï¼Œä½†å®ƒç›®å‰ç¼ºä¹æ ‡å‡†çš„å¯äº’æ“ä½œæ•°æ®ç±»å‹ã€‚è¿™æ„å‘³ç€LangChainåœ¨å¤„ç†æ•°æ®æ—¶å¯èƒ½éœ€è¦è¿›è¡Œä¸€äº›é¢å¤–çš„å¤„ç†å’Œè½¬æ¢ã€‚å¼€å‘äººå‘˜å¯ä»¥æ ¹æ®è‡ªå·±çš„éœ€æ±‚ä½¿ç”¨LangChainæä¾›çš„åŠŸèƒ½å’Œå·¥å…·æ¥å¤„ç†å’Œæ“ä½œæ•°æ®ã€‚
        
        </aside>
        
10. LangChain æ›¿ä»£æ–¹æ¡ˆï¼Ÿ
    
    <aside>
    ğŸ’¡ LangChainæ˜¯ä¸€ä¸ªç‹¬ç‰¹çš„æ¡†æ¶ï¼Œç›®å‰æ²¡æœ‰ç›´æ¥çš„æ›¿ä»£æ–¹æ¡ˆã€‚å®ƒæä¾›äº†ä¸€ç§ç®€åŒ–å¼€å‘è¿‡ç¨‹çš„æ–¹å¼ï¼Œä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿæ›´è½»æ¾åœ°æ„å»ºåŸºäºè¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åºã€‚LangChainçš„ç‰¹ç‚¹åŒ…æ‹¬ç¼–å†™è‡ªå®šä¹‰çš„LangChainæç¤ºå’Œé“¾å¼ä»£ç çš„è¯­æ³•ç³–ã€ä½¿ç”¨IDEå†…ç½®çš„æ”¯æŒè¿›è¡Œæç¤ºå’Œç±»å‹æ£€æŸ¥ã€æ”¯æŒå¯é€‰å‚æ•°å’Œå…±äº«å‚æ•°ç­‰ã€‚è™½ç„¶å¯èƒ½æœ‰å…¶ä»–ç±»ä¼¼çš„æ¡†æ¶å¯ç”¨ï¼Œä½†LangChainåœ¨å…¶ç‰¹å®šé¢†åŸŸå†…æä¾›äº†ç‹¬ç‰¹çš„åŠŸèƒ½å’Œä¼˜åŠ¿ã€‚
    
    </aside>
